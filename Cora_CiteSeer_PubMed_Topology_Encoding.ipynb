{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcaVvKvsHKw6"
      },
      "outputs": [],
      "source": [
        "pip install ogb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRMchmRhHpZ0"
      },
      "outputs": [],
      "source": [
        "pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "import time\n",
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.utils import to_undirected\n",
        "from torch_geometric.nn import LabelPropagation\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "\n",
        "# -------------------------------\n",
        "# Config\n",
        "# -------------------------------\n",
        "root = './data/Planetoid'\n",
        "datasets = ['Cora', 'CiteSeer', 'PubMed']\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "LP_LAYERS = 1\n",
        "LP_ALPHA  = 1.0\n",
        "\n",
        "# -------------------------------\n",
        "# Normalization helper\n",
        "# -------------------------------\n",
        "@torch.no_grad()\n",
        "def normalize_adjs(edge_index, num_nodes, edge_weight=None, eps=1e-12):\n",
        "    \"\"\"\n",
        "    Return normalized (edge_index, edge_weight) for:\n",
        "    - DAD (symmetric): D^{-1/2} A D^{-1/2}\n",
        "    - GCN-DAD: symmetric with self-loops (gcn_norm)\n",
        "    - DA  (row):       D^{-1} A\n",
        "    - AD  (col):       A D^{-1}\n",
        "    Works for directed & weighted graphs.\n",
        "    \"\"\"\n",
        "    if edge_weight is None:\n",
        "        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n",
        "\n",
        "    row, col = edge_index\n",
        "    deg = torch.zeros(num_nodes, device=edge_weight.device).scatter_add_(0, row, edge_weight)\n",
        "    deg_inv = (1.0 / deg.clamp_min(eps))\n",
        "    deg_inv_sqrt = deg_inv.sqrt()\n",
        "\n",
        "    # DAD (no self-loops)\n",
        "    dad_w = deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
        "\n",
        "    # GCN-style DAD (with self-loops)\n",
        "    gcn_ei, gcn_w = gcn_norm(\n",
        "        edge_index=edge_index, edge_weight=edge_weight,\n",
        "        num_nodes=num_nodes, add_self_loops=True\n",
        "    )\n",
        "\n",
        "    # DA (row-normalized)\n",
        "    da_w = deg_inv[row] * edge_weight\n",
        "    # AD (col-normalized)\n",
        "    ad_w = deg_inv[col] * edge_weight\n",
        "\n",
        "    return (edge_index, dad_w), (gcn_ei, gcn_w), (edge_index, da_w), (edge_index, ad_w)\n",
        "\n",
        "# -------------------------------\n",
        "# Sparse helpers\n",
        "# -------------------------------\n",
        "def build_sparse_from_edge_index(edge_index, num_nodes, weight=None, dtype=torch.float32):\n",
        "    if weight is None:\n",
        "        weight = torch.ones(edge_index.size(1), device=edge_index.device, dtype=dtype)\n",
        "    return torch.sparse_coo_tensor(edge_index, weight, (num_nodes, num_nodes)).coalesce()\n",
        "\n",
        "# -------------------------------\n",
        "# LP runner\n",
        "# -------------------------------\n",
        "@torch.no_grad()\n",
        "def run_lp(edge_index, edge_weight, y, train_mask, val_mask, test_mask, name=\"\"):\n",
        "    model = LabelPropagation(num_layers=LP_LAYERS, alpha=LP_ALPHA)\n",
        "    out = model(y, edge_index, mask=train_mask, edge_weight=edge_weight)\n",
        "    y_pred = out.argmax(dim=-1)\n",
        "\n",
        "    def acc(mask):\n",
        "        if mask.sum() == 0:\n",
        "            return float('nan')\n",
        "        return (y_pred[mask] == y[mask]).float().mean().item()\n",
        "\n",
        "    tr, va, te = acc(train_mask), acc(val_mask), acc(test_mask)\n",
        "    print(f\"[{name}] Train: {tr:.4f} | Val: {va:.4f} | Test: {te:.4f}\")\n",
        "    return {\"train\": tr, \"valid\": va, \"test\": te}\n",
        "\n",
        "# -------------------------------\n",
        "# Evaluate one graph with 4 norms\n",
        "# -------------------------------\n",
        "def evaluate_graph(tag, edge_index, edge_weight, y, train_mask, val_mask, test_mask, num_nodes):\n",
        "    results = {}\n",
        "    (DAD, GCN_DAD, DA, AD) = normalize_adjs(edge_index, num_nodes, edge_weight)\n",
        "\n",
        "    results[\"DAD\"]     = run_lp(*DAD,     y, train_mask, val_mask, test_mask, f\"{tag} LP (DAD)\")\n",
        "    results[\"GCN-DAD\"] = run_lp(*GCN_DAD, y, train_mask, val_mask, test_mask, f\"{tag} LP (GCN-DAD)\")\n",
        "    results[\"DA\"]      = run_lp(*DA,      y, train_mask, val_mask, test_mask, f\"{tag} LP (DA)\")\n",
        "    results[\"AD\"]      = run_lp(*AD,      y, train_mask, val_mask, test_mask, f\"{tag} LP (AD)\")\n",
        "    return results\n",
        "\n",
        "# -------------------------------\n",
        "# Main loop over datasets\n",
        "# -------------------------------\n",
        "all_results = {}\n",
        "\n",
        "for name in datasets:\n",
        "    print(f\"\\n================= {name} =================\")\n",
        "    ds = Planetoid(root=osp.join(root, name), name=name)\n",
        "    data = ds[0].to(device)\n",
        "\n",
        "    # Ensure original is undirected\n",
        "    edge_index_A = to_undirected(data.edge_index, num_nodes=data.num_nodes)\n",
        "    y = data.y\n",
        "\n",
        "    print(f\"nodes: {data.num_nodes}, edges: {edge_index_A.size(1)}\")\n",
        "    print(f\"masks: train={int(data.train_mask.sum())}, val={int(data.val_mask.sum())}, test={int(data.test_mask.sum())}\\n\")\n",
        "\n",
        "    # ---------- Original A ----------\n",
        "    print(\"=== Original Graph (A) ===\")\n",
        "    results_A = evaluate_graph(\n",
        "        f\"{name}\",\n",
        "        edge_index_A, None,\n",
        "        y, data.train_mask, data.val_mask, data.test_mask,\n",
        "        data.num_nodes\n",
        "    )\n",
        "\n",
        "    # ---------- Transformed DMI = 2D + D^2 ----------\n",
        "    print(\"\\n=== Transformed Graph (SNN(beta,(1,1))) ===\")\n",
        "    D = build_sparse_from_edge_index(data.edge_index, data.num_nodes, dtype=torch.float32)\n",
        "    torch.cuda.empty_cache()\n",
        "    t0 = time.time()\n",
        "    D2 = torch.sparse.mm(D, D)\n",
        "    D3 = torch.sparse.mm(D, D2)\n",
        "    DMI = 2*D+D2\n",
        "    t1 = time.time()\n",
        "    print(f\"SNN(beta,(1,1)) built in {t1 - t0:.4f}s\")\n",
        "\n",
        "    # Keep DMI as-is (weighted, directed, no symmetrization)\n",
        "    w = DMI.coalesce()\n",
        "    ei_dmi, ew_dmi = w.indices(), w.values()\n",
        "\n",
        "    results_DMI = evaluate_graph(\n",
        "        f\"{name}-DMI\",\n",
        "        ei_dmi, ew_dmi,\n",
        "        y, data.train_mask, data.val_mask, data.test_mask,\n",
        "        data.num_nodes\n",
        "    )\n",
        "\n",
        "    # ---------- Summary for this dataset ----------\n",
        "    all_results[name] = {\"A\": results_A, \"DMI\": results_DMI}\n",
        "\n",
        "# -------------------------------\n",
        "# Final summary\n",
        "# -------------------------------\n",
        "print(\"\\n================= SUMMARY =================\")\n",
        "for name in datasets:\n",
        "    print(f\"\\n{name} (Original A):\")\n",
        "    for norm, accs in all_results[name][\"A\"].items():\n",
        "        print(f\"{norm:8s} -> Train: {accs['train']:.4f} | Val: {accs['valid']:.4f} | Test: {accs['test']:.4f}\")\n",
        "    print(f\"\\n{name} (SNN(beta,(1,1)):\")\n",
        "    for norm, accs in all_results[name][\"DMI\"].items():\n",
        "        print(f\"{norm:8s} -> Train: {accs['train']:.4f} | Val: {accs['valid']:.4f} | Test: {accs['test']:.4f}\")\n"
      ],
      "metadata": {
        "id": "b-w3-gO9i9kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "import time\n",
        "import torch\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.utils import to_undirected\n",
        "from torch_geometric.nn import LabelPropagation\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "\n",
        "# -------------------------------\n",
        "# Config\n",
        "# -------------------------------\n",
        "root = './data/Planetoid'\n",
        "datasets = ['Cora', 'CiteSeer', 'PubMed']\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "LP_LAYERS = 1\n",
        "LP_ALPHA  = 1.0\n",
        "\n",
        "# -------------------------------\n",
        "# Normalization helper\n",
        "# -------------------------------\n",
        "@torch.no_grad()\n",
        "def normalize_adjs(edge_index, num_nodes, edge_weight=None, eps=1e-12):\n",
        "    \"\"\"\n",
        "    Return normalized (edge_index, edge_weight) for:\n",
        "    - DAD (symmetric): D^{-1/2} A D^{-1/2}\n",
        "    - GCN-DAD: symmetric with self-loops (gcn_norm)\n",
        "    - DA  (row):       D^{-1} A\n",
        "    - AD  (col):       A D^{-1}\n",
        "    Works for directed & weighted graphs.\n",
        "    \"\"\"\n",
        "    if edge_weight is None:\n",
        "        edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n",
        "\n",
        "    row, col = edge_index\n",
        "    deg = torch.zeros(num_nodes, device=edge_weight.device).scatter_add_(0, row, edge_weight)\n",
        "    deg_inv = (1.0 / deg.clamp_min(eps))\n",
        "    deg_inv_sqrt = deg_inv.sqrt()\n",
        "\n",
        "    # DAD (no self-loops)\n",
        "    dad_w = deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
        "\n",
        "    # GCN-style DAD (with self-loops)\n",
        "    gcn_ei, gcn_w = gcn_norm(\n",
        "        edge_index=edge_index, edge_weight=edge_weight,\n",
        "        num_nodes=num_nodes, add_self_loops=True\n",
        "    )\n",
        "\n",
        "    # DA (row-normalized)\n",
        "    da_w = deg_inv[row] * edge_weight\n",
        "    # AD (col-normalized)\n",
        "    ad_w = deg_inv[col] * edge_weight\n",
        "\n",
        "    return (edge_index, dad_w), (gcn_ei, gcn_w), (edge_index, da_w), (edge_index, ad_w)\n",
        "\n",
        "# -------------------------------\n",
        "# Sparse helpers\n",
        "# -------------------------------\n",
        "def build_sparse_from_edge_index(edge_index, num_nodes, weight=None, dtype=torch.float32):\n",
        "    if weight is None:\n",
        "        weight = torch.ones(edge_index.size(1), device=edge_index.device, dtype=dtype)\n",
        "    return torch.sparse_coo_tensor(edge_index, weight, (num_nodes, num_nodes)).coalesce()\n",
        "\n",
        "# -------------------------------\n",
        "# LP runner\n",
        "# -------------------------------\n",
        "@torch.no_grad()\n",
        "def run_lp(edge_index, edge_weight, y, train_mask, val_mask, test_mask, name=\"\"):\n",
        "    model = LabelPropagation(num_layers=LP_LAYERS, alpha=LP_ALPHA)\n",
        "    out = model(y, edge_index, mask=train_mask, edge_weight=edge_weight)\n",
        "    y_pred = out.argmax(dim=-1)\n",
        "\n",
        "    def acc(mask):\n",
        "        if mask.sum() == 0:\n",
        "            return float('nan')\n",
        "        return (y_pred[mask] == y[mask]).float().mean().item()\n",
        "\n",
        "    tr, va, te = acc(train_mask), acc(val_mask), acc(test_mask)\n",
        "    print(f\"[{name}] Train: {tr:.4f} | Val: {va:.4f} | Test: {te:.4f}\")\n",
        "    return {\"train\": tr, \"valid\": va, \"test\": te}\n",
        "\n",
        "# -------------------------------\n",
        "# Evaluate one graph with 4 norms\n",
        "# -------------------------------\n",
        "def evaluate_graph(tag, edge_index, edge_weight, y, train_mask, val_mask, test_mask, num_nodes):\n",
        "    results = {}\n",
        "    (DAD, GCN_DAD, DA, AD) = normalize_adjs(edge_index, num_nodes, edge_weight)\n",
        "\n",
        "    results[\"DAD\"]     = run_lp(*DAD,     y, train_mask, val_mask, test_mask, f\"{tag} LP (DAD)\")\n",
        "    results[\"GCN-DAD\"] = run_lp(*GCN_DAD, y, train_mask, val_mask, test_mask, f\"{tag} LP (GCN-DAD)\")\n",
        "    results[\"DA\"]      = run_lp(*DA,      y, train_mask, val_mask, test_mask, f\"{tag} LP (DA)\")\n",
        "    results[\"AD\"]      = run_lp(*AD,      y, train_mask, val_mask, test_mask, f\"{tag} LP (AD)\")\n",
        "    return results\n",
        "\n",
        "# -------------------------------\n",
        "# Main loop over datasets\n",
        "# -------------------------------\n",
        "all_results = {}\n",
        "\n",
        "for name in datasets:\n",
        "    print(f\"\\n================= {name} =================\")\n",
        "    ds = Planetoid(root=osp.join(root, name), name=name)\n",
        "    data = ds[0].to(device)\n",
        "\n",
        "    # Ensure original is undirected\n",
        "    edge_index_A = to_undirected(data.edge_index, num_nodes=data.num_nodes)\n",
        "    y = data.y\n",
        "\n",
        "    print(f\"nodes: {data.num_nodes}, edges: {edge_index_A.size(1)}\")\n",
        "    print(f\"masks: train={int(data.train_mask.sum())}, val={int(data.val_mask.sum())}, test={int(data.test_mask.sum())}\\n\")\n",
        "\n",
        "    # ---------- Original A ----------\n",
        "    print(\"=== Original Graph (A) ===\")\n",
        "    results_A = evaluate_graph(\n",
        "        f\"{name}\",\n",
        "        edge_index_A, None,\n",
        "        y, data.train_mask, data.val_mask, data.test_mask,\n",
        "        data.num_nodes\n",
        "    )\n",
        "\n",
        "    # ---------- Transformed DMI = 2D + D^2 ----------\n",
        "    print(\"\\n=== Transformed Graph (SNN(beta,(1,1,1))) ===\")\n",
        "    D = build_sparse_from_edge_index(data.edge_index, data.num_nodes, dtype=torch.float32)\n",
        "    torch.cuda.empty_cache()\n",
        "    t0 = time.time()\n",
        "    D2 = torch.sparse.mm(D, D)\n",
        "    D3 = torch.sparse.mm(D, D2)\n",
        "    DMI = 3*D + 3*D2 + D3\n",
        "    t1 = time.time()\n",
        "    print(f\"SNN(beta,(1,1,1)) built in {t1 - t0:.4f}s\")\n",
        "\n",
        "    # Keep DMI as-is (weighted, directed, no symmetrization)\n",
        "    w = DMI.coalesce()\n",
        "    ei_dmi, ew_dmi = w.indices(), w.values()\n",
        "\n",
        "    results_DMI = evaluate_graph(\n",
        "        f\"{name}-DMI\",\n",
        "        ei_dmi, ew_dmi,\n",
        "        y, data.train_mask, data.val_mask, data.test_mask,\n",
        "        data.num_nodes\n",
        "    )\n",
        "\n",
        "    # ---------- Summary for this dataset ----------\n",
        "    all_results[name] = {\"A\": results_A, \"DMI\": results_DMI}\n",
        "\n",
        "# -------------------------------\n",
        "# Final summary\n",
        "# -------------------------------\n",
        "print(\"\\n================= SUMMARY =================\")\n",
        "for name in datasets:\n",
        "    print(f\"\\n{name} (Original A):\")\n",
        "    for norm, accs in all_results[name][\"A\"].items():\n",
        "        print(f\"{norm:8s} -> Train: {accs['train']:.4f} | Val: {accs['valid']:.4f} | Test: {accs['test']:.4f}\")\n",
        "    print(f\"\\n{name} (SNN(beta,(1,1,1)):\")\n",
        "    for norm, accs in all_results[name][\"DMI\"].items():\n",
        "        print(f\"{norm:8s} -> Train: {accs['train']:.4f} | Val: {accs['valid']:.4f} | Test: {accs['test']:.4f}\")\n"
      ],
      "metadata": {
        "id": "lLgIhYvdSxXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S6iE-tkaZSrv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
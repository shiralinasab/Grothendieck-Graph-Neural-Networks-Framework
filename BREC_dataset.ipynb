{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffec5cc1-fdba-4f14-ba72-bf9c8a7f19ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_undirected\n",
    "import torch.nn.functional as F\n",
    "from brec.dataset import BRECDataset\n",
    "from brec.evaluator import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3a0a2-45ab-464d-aeba-c0061c22dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mon_op(A, B):\n",
    "    return A + B + torch.mm(A, B)\n",
    "\n",
    "def image(X,n,m):\n",
    "    cover=torch.zeros(n,n,n).to(torch.float64)\n",
    "    for i in range(n):\n",
    "        \n",
    "        dec=torch.clone(X)\n",
    "        cover[i].t()[i]=X.t()[i]\n",
    "        dec[i]=0\n",
    "        dec.t()[i]=0\n",
    "        M=torch.zeros(n,n).to(torch.float64)\n",
    "        N=torch.ones(n,n).to(torch.float64)\n",
    "        for k in range(n):\n",
    "            if cover[i][k].sum()!=0:\n",
    "                M.t()[k]=1\n",
    "                N.t()[k]=0\n",
    "        c=0\n",
    "            #M.sum()!=0  c<m \n",
    "        while M.sum()!=0:\n",
    "            cover[i]=mon_op((M*dec)-(((M*dec)*((M*dec).t()))),cover[i])\n",
    "            dec=dec-(M*dec)\n",
    "            M=torch.zeros(n,n).to(torch.float64)\n",
    "            N=torch.ones(n,n).to(torch.float64)\n",
    "            for k_ in range(n):\n",
    "                if cover[i][k_].sum()!=0 and dec.t()[k_].sum()!=0:\n",
    "                    M.t()[k_]=1\n",
    "                    N.t()[k_]=0\n",
    "            c+=1\n",
    "            \n",
    "    return torch.log1p(cover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa78522-5ea9-4c26-9f51-4d782bb7b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"We utilized the Non-GNNs code from the BREC dataset repository (https://github.com/GraphPKU/BREC/tree/Release/Non-GNNs)\n",
    "and integrated our code as a function named snn within this framework.\"\"\"\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(2022)\n",
    "random.seed(2022)\n",
    "\n",
    "# Placeholder functions for methods not used\n",
    "def func_None():\n",
    "    raise NotImplementedError(f\"Cannot find func {args.method}\")\n",
    "\n",
    "# Your custom model function\n",
    "import networkx as nx\n",
    "import torch\n",
    "\n",
    "def snn(gr):\n",
    "    # Ensure the input is a NetworkX graph\n",
    "    if not isinstance(gr, nx.Graph):\n",
    "        raise TypeError(f\"Expected a NetworkX graph, got {type(gr)}\")\n",
    "    \n",
    "    # Get the number of nodes and edges\n",
    "    num_nodes = gr.number_of_nodes()\n",
    "    num_edges = gr.number_of_edges()\n",
    "    \n",
    "    # Create adjacency matrix from the graph\n",
    "    Ad_mat = torch.tensor(nx.to_numpy_array(gr), dtype=torch.float64)\n",
    "    # Apply custom processing\n",
    "    Image = image(Ad_mat, num_nodes,20)  # Ensure `image` function works as expected\n",
    "    su = torch.sum(Image, 0)\n",
    "    output_snn_beta = mon_op(mon_op(su.t(),su)**(1/2),mon_op(su.t(),su)**(1/2))\n",
    "    s = torch.var(output_snn_beta)\n",
    "    det=torch.linalg.det(output_snn_beta)\n",
    "    det_su=torch.linalg.det(su)\n",
    "    return (det,s)\n",
    "\n",
    "\n",
    "# Dictionary mapping methods to their respective functions\n",
    "func_dict = {\n",
    "    \"fwl\": func_None,  # Replace with actual implementation if needed\n",
    "    \"wl\": func_None,   # Replace with actual implementation if needed\n",
    "    \"snn\": snn,  # Your model is added here\n",
    "}\n",
    "\n",
    "def wl_method(method, G, k=None, mode=None):\n",
    "    return func_dict.get(method, func_None)(G)\n",
    "\n",
    "# Define dataset partitions\n",
    "part_dict = {\n",
    "    \"Basic\": (0, 60),\n",
    "    \"Regular\": (60, 160),\n",
    "    \"Extension\": (160, 260),\n",
    "    \"CFI\": (260, 360),\n",
    "    \"4-Vertex_Condition\": (360, 380),\n",
    "    \"Distance_Regular\": (380, 400),\n",
    "    \"Reliability\": (400, 800),\n",
    "}\n",
    "\n",
    "# Handle argument parsing for terminal and interactive environments\n",
    "if len(sys.argv) > 1 and \"--file\" in sys.argv:\n",
    "    parser = argparse.ArgumentParser(description=\"Test non-GNN methods on BREC.\")\n",
    "    parser.add_argument(\"--file\", type=str, default=\"brec_nonGNN.npy\")\n",
    "    parser.add_argument(\"--method\", type=str, default=\"snn\")\n",
    "    parser.add_argument(\"--graph_type\", type=str, default=\"none\")\n",
    "    args = parser.parse_args()\n",
    "else:\n",
    "    # Manual argument setup for interactive environments\n",
    "    class Args:\n",
    "        file = r\"C:\\Users\\shira\\Downloads\\brec_nonGNN.npy\"  # Path to the dataset file\n",
    "        method = \"snn\"      # Your method\n",
    "        graph_type = \"none\"      # Default graph type\n",
    "\n",
    "    args = Args()\n",
    "\n",
    "G_TYPE = args.graph_type.strip()\n",
    "if G_TYPE == \"none\":\n",
    "    method_name = args.method\n",
    "else:\n",
    "    if G_TYPE in part_dict:\n",
    "        method_name = f\"{args.method}_{G_TYPE}\"\n",
    "    else:\n",
    "        raise NotImplementedError(f\"{G_TYPE} does not exist!\")\n",
    "\n",
    "path = os.path.join(\"result\", method_name)\n",
    "os.makedirs(path, exist_ok=True)\n",
    "os.makedirs(os.path.join(path, \"part_result\"), exist_ok=True)\n",
    "\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "DATE_FORMAT = \"%m/%d/%Y %H:%M:%S %p\"\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(path, \"logging.log\"),\n",
    "    level=logging.INFO,\n",
    "    format=LOG_FORMAT,\n",
    "    datefmt=DATE_FORMAT,\n",
    ")\n",
    "logging.info(args)\n",
    "\n",
    "def count_distinguish_num(graph_tuple_list):\n",
    "    logging.info(f\"{method_name} test starting ---\")\n",
    "    print(f\"{method_name} test starting ---\")\n",
    "\n",
    "    cnt = 0\n",
    "    correct_list = []\n",
    "    time_cost = 0\n",
    "    DATA_NUM = (\n",
    "        400 if G_TYPE == \"none\" else int(part_dict[G_TYPE][1] - part_dict[G_TYPE][0])\n",
    "    )\n",
    "\n",
    "    for part_name, part_range in part_dict.items():\n",
    "        if not (G_TYPE == \"none\" or G_TYPE == part_name):\n",
    "            continue\n",
    "\n",
    "        logging.info(f\"{part_name} part starting ---\")\n",
    "\n",
    "        cnt_part = 0\n",
    "        correct_list_part = []\n",
    "        start = time.process_time()\n",
    "\n",
    "        for id in tqdm(range(part_range[0], part_range[1])):\n",
    "            graph_tuple = graph_tuple_list[id]\n",
    "            if not wl_method(\n",
    "                args.method, graph_tuple[0]\n",
    "            ) == wl_method(args.method, graph_tuple[1]):\n",
    "                cnt += 1\n",
    "                cnt_part += 1\n",
    "                correct_list.append(id)\n",
    "                correct_list_part.append(id)\n",
    "            else:\n",
    "                logging.info(f\"Wrong in {id}\")\n",
    "\n",
    "        end = time.process_time()\n",
    "        time_cost_part = round(end - start, 2)\n",
    "        time_cost += time_cost_part\n",
    "\n",
    "        logging.info(\n",
    "            f\"{part_name} part costs time {time_cost_part}; Correct in {cnt_part} / {part_range[1] - part_range[0]}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"{part_name} part costs time {time_cost_part}; Correct in {cnt_part} / {part_range[1] - part_range[0]}\"\n",
    "        )\n",
    "        np.save(os.path.join(path, \"part_result\", part_name), correct_list_part)\n",
    "\n",
    "    time_cost = round(time_cost, 2)\n",
    "    Acc = round(cnt / DATA_NUM, 2)\n",
    "\n",
    "    logging.info(f\"Costs time {time_cost}; Correct in {cnt} / {DATA_NUM}, Acc = {Acc}\")\n",
    "    print(f\"Costs time {time_cost}; Correct in {cnt} / {DATA_NUM}, Acc = {Acc}\")\n",
    "\n",
    "    np.save(os.path.join(path, \"result\"), correct_list)\n",
    "\n",
    "    return\n",
    "\n",
    "def main():\n",
    "    graph_tuple_list = np.load(args.file, allow_pickle=True)\n",
    "    \n",
    "    \n",
    "    print(\"First item in graph_tuple_list:\", graph_tuple_list[0])  # Print the first item for inspection\n",
    "    print(\"Type of first graph in tuple:\", type(graph_tuple_list[0][0]))  # Check the type of the graph\n",
    "    count_distinguish_num(graph_tuple_list)\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9af4f5-a33b-4ccc-ab4c-7451514a0f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
